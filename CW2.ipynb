{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework 2 \n",
    "### Perform k-nearest neighbour (KNN) retrieval experiments according to standard practices in pattern recognition. Use retrieval error (ie @rank1, @rank10) as the performance metric to evaluate different methods. Your baseline approach is KNN on provided features. Use distance metric learning methods to improve a baseline performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So, firstly, we need to create a baseline, which is KNN on provided features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "train_idxs = loadmat('cuhk03_new_protocol_config_labeled.mat')['train_idx'].flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (14096, 2048)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open(\"PR_data/feature_data.json\", \"r\") as file:\n",
    "    features = json.load(file)\n",
    "    \n",
    "data_features = np.asarray(features)\n",
    "\n",
    "print('Data shape: {}'.format(data_features.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training indexes : (7368,)\n",
      "query indexes : (1400,)\n",
      "gallery indexes : (5328,)\n"
     ]
    }
   ],
   "source": [
    "#Load labels\n",
    "labelss = loadmat('cuhk03_new_protocol_config_labeled.mat')['labels'].flatten()\n",
    "\n",
    "#Load camId\n",
    "cam_Ids = loadmat('cuhk03_new_protocol_config_labeled.mat')['camId'].flatten()\n",
    "\n",
    "#Load indexes\n",
    "train_idxs = loadmat('cuhk03_new_protocol_config_labeled.mat')['train_idx'].flatten()\n",
    "query_idxs = loadmat('cuhk03_new_protocol_config_labeled.mat')['query_idx'].flatten()\n",
    "gallery_idxs = loadmat('cuhk03_new_protocol_config_labeled.mat')['gallery_idx'].flatten()\n",
    "\n",
    "#Load training indexes\n",
    "print(\"training indexes : {}\".format(train_idxs.shape))\n",
    "print(\"query indexes : {}\".format( query_idxs.shape))\n",
    "print(\"gallery indexes : {}\".format( gallery_idxs.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to python index notation\n",
    "\n",
    "train_idxs = train_idxs - 1\n",
    "query_idxs = query_idxs - 1\n",
    "gallery_idxs = gallery_idxs - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate the features and data into training, query and gallery sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f = []\n",
    "train_label = []\n",
    "\n",
    "# divide the features data into training \n",
    "for i in range (len(train_idxs)):\n",
    "    train_f.append(data_features[train_idxs[i]])\n",
    "    train_camid.append(cam_Ids[train_idxs[i]])\n",
    "    train_label.append(labelss[train_idxs[i]])\n",
    "    \n",
    "train_f = np.asarray(train_f)    \n",
    "train_label = np.asarray(train_label)\n",
    "train_camid = np.asarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features, cam, label data into gallery\n",
    "query_f = []\n",
    "query_camid = []\n",
    "query_label = []\n",
    "\n",
    "for i in range (len(query_idxs)):\n",
    "    query_f.append(data_features[query_idxs[i]])\n",
    "    query_camid.append(cam_Ids[query_idxs[i]])\n",
    "    query_label.append(labelss[query_idxs[i]])\n",
    "    \n",
    "query_f = np.asarray(query_f) \n",
    "query_label = np.asarray(query_label)\n",
    "query_camid = np.asarray(query_camid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features, cam, label data into gallery\n",
    "gallery_f = []\n",
    "gallery_camid = []\n",
    "gallery_label = []\n",
    "\n",
    "for i in range (len(gallery_idxs)):\n",
    "    gallery_f.append(data_features[gallery_idxs[i]])\n",
    "    gallery_camid.append(cam_Ids[gallery_idxs[i]])\n",
    "    gallery_label.append(labelss[gallery_idxs[i]])\n",
    "       \n",
    "gallery_f = np.asarray(gallery_f)  \n",
    "gallery_camid = np.asarray(gallery_camid)  \n",
    "gallery_label = np.asarray(gallery_label)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate query and gallery features/labels/cam ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   3.    3.    6. ... 1461. 1463. 1463.]\n",
      "(5328, 2050)\n"
     ]
    }
   ],
   "source": [
    "#stacking labels, cam ids and features\n",
    "\n",
    "query = np.vstack((query_f.T, query_label, query_camid)) #transpose feature matrix to match dimensions \n",
    "gallery = np.vstack((gallery_f.T, gallery_label, gallery_camid)) #transpose feature matrix to match dimensions \n",
    "\n",
    "#transpose back to get right shape\n",
    "query = query.T\n",
    "gallery = gallery.T\n",
    "\n",
    "print(query[:,-2])\n",
    "print(gallery.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the repetitions of cam ids and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 54.447789907455444 seconds ---\n",
      "(5324, 2050)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range (len(query[:,0])):\n",
    "    gallery_no_rep = gallery[~np.logical_and((gallery[:,-1] == query[i, -1]), (gallery[:,-2] == query[i, -2]))]\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print(gallery_no_rep.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbor Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "k = 10 #number of nearest neighbors parameter\n",
    "\n",
    "rank = []\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "##sqeuclidean instead of euclidean for computing efficientcy. As we are only interested in the ranklists\n",
    "##and not the actual values of the distances.\n",
    "NN = NearestNeighbors(n_neighbors = k, metric = 'sqeuclidean') #setting up NN\n",
    "NN.fit(gallery_no_rep[:,:-2], gallery_no_rep[:,-2])\n",
    "\n",
    "dist, idxs = NN.kneighbors(query_f)\n",
    "\n",
    "for i in range (len(query[:,0])):\n",
    "    row_rank = []\n",
    "    for j in range (len(idxs[0,:])):\n",
    "        row_rank.append(gallery[idxs[i,j],-2])\n",
    "    rank.append(row_rank)\n",
    "    \n",
    "rank = np.asarray(rank)     \n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "#print(dist)\n",
    "#print(idxs)\n",
    "print(query_label)\n",
    "print(rank.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6.   6.   6.   6.   6.   6.   6.   6. 678.  77.]\n"
     ]
    }
   ],
   "source": [
    "print(rank[2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
